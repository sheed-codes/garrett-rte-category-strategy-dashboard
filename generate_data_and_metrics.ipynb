{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Garrett RTE Category Manager Analytics (Mock Nielsen-style)\n",
        "# Colab + Looker Studio ready\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# --- Config ---\n",
        "SEED = 33\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# In Colab, you can save to /content. Later we will optionally save to Google Drive.\n",
        "DATA_DIR = \"/content/data\"\n",
        "OUT_DIR = \"/content/outputs\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"rte_scanner_mock.csv\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 1) Generate synthetic \"syndicated-like\" scanner data\n",
        "# --------------------------------------------\n",
        "def generate_mock_scanner_data():\n",
        "    weeks = pd.date_range(\"2024-03-03\", periods=52, freq=\"W-SUN\")\n",
        "    retailers = [\"Walmart\", \"Target\", \"Kroger\", \"Walgreens\", \"Costco\", \"Meijer\"]\n",
        "    regions = [\"Midwest\", \"Northeast\", \"South\", \"West\"]\n",
        "    brands = [\"Garrett\", \"Competitor A\", \"Competitor B\"]\n",
        "\n",
        "    skus = [\n",
        "        (\"Cheddar 6oz\", 5.49),\n",
        "        (\"Caramel 6oz\", 5.29),\n",
        "        (\"Mix 10oz\", 8.99),\n",
        "        (\"Caramel 10oz\", 8.49),\n",
        "        (\"Cheddar 10oz\", 8.79),\n",
        "        (\"Variety 12pk\", 18.99),\n",
        "    ]\n",
        "\n",
        "    retailer_cat_mult = {\n",
        "        \"Walmart\": 1.30,\n",
        "        \"Target\": 1.10,\n",
        "        \"Kroger\": 1.05,\n",
        "        \"Walgreens\": 0.75,\n",
        "        \"Costco\": 1.25,\n",
        "        \"Meijer\": 0.90,\n",
        "    }\n",
        "\n",
        "    brand_mult = {\"Garrett\": 0.95, \"Competitor A\": 1.10, \"Competitor B\": 0.85}\n",
        "    region_mult = {\"Midwest\": 1.15, \"Northeast\": 1.00, \"South\": 0.92, \"West\": 0.96}\n",
        "\n",
        "    sku_pop = {\n",
        "        \"Cheddar 6oz\": 1.15,\n",
        "        \"Caramel 6oz\": 1.05,\n",
        "        \"Mix 10oz\": 1.25,\n",
        "        \"Caramel 10oz\": 0.95,\n",
        "        \"Cheddar 10oz\": 1.00,\n",
        "        \"Variety 12pk\": 0.70,\n",
        "    }\n",
        "\n",
        "    # Distribution proxy: stores_selling\n",
        "    # Make Garrett underdistributed at Walmart and Costco to create whitespace opportunities\n",
        "    base_stores = {\n",
        "        (\"Garrett\", \"Walmart\"): 350,\n",
        "        (\"Garrett\", \"Target\"): 420,\n",
        "        (\"Garrett\", \"Kroger\"): 280,\n",
        "        (\"Garrett\", \"Walgreens\"): 210,\n",
        "        (\"Garrett\", \"Costco\"): 120,\n",
        "        (\"Garrett\", \"Meijer\"): 160,\n",
        "        (\"Competitor A\", \"Walmart\"): 700,\n",
        "        (\"Competitor A\", \"Target\"): 560,\n",
        "        (\"Competitor A\", \"Kroger\"): 610,\n",
        "        (\"Competitor A\", \"Walgreens\"): 420,\n",
        "        (\"Competitor A\", \"Costco\"): 210,\n",
        "        (\"Competitor A\", \"Meijer\"): 300,\n",
        "        (\"Competitor B\", \"Walmart\"): 420,\n",
        "        (\"Competitor B\", \"Target\"): 380,\n",
        "        (\"Competitor B\", \"Kroger\"): 340,\n",
        "        (\"Competitor B\", \"Walgreens\"): 260,\n",
        "        (\"Competitor B\", \"Costco\"): 160,\n",
        "        (\"Competitor B\", \"Meijer\"): 210,\n",
        "    }\n",
        "\n",
        "    promo_prob = {\"Walmart\": 0.22, \"Target\": 0.28, \"Kroger\": 0.33, \"Walgreens\": 0.25, \"Costco\": 0.12, \"Meijer\": 0.30}\n",
        "    feature_prob = {\"Walmart\": 0.12, \"Target\": 0.18, \"Kroger\": 0.20, \"Walgreens\": 0.10, \"Costco\": 0.08, \"Meijer\": 0.16}\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for w in weeks:\n",
        "        week_index = (w - weeks.min()).days / 7\n",
        "        season = 1.0 + 0.10 * np.sin(2 * np.pi * week_index / 52) + 0.05 * np.cos(2 * np.pi * week_index / 26)\n",
        "\n",
        "        for retailer in retailers:\n",
        "            for region in regions:\n",
        "                for brand in brands:\n",
        "                    for sku, base_price in skus:\n",
        "                        promo_flag = int(np.random.rand() < promo_prob[retailer])\n",
        "                        feature_display = int(np.random.rand() < feature_prob[retailer])\n",
        "\n",
        "                        discount = np.random.uniform(0.08, 0.25) if promo_flag else 0.0\n",
        "                        price = round(base_price * (1 - discount), 2)\n",
        "\n",
        "                        # stores selling: small noise + gentle growth trend\n",
        "                        base = base_stores[(brand, retailer)]\n",
        "                        growth = 1.0 + 0.04 * (week_index / 52)  # ~4% growth across the year\n",
        "                        stores_selling = int(max(25, np.random.normal(loc=base * growth, scale=base * 0.03)))\n",
        "\n",
        "                        # Demand model: base demand * multipliers * seasonality * promo/feature lift\n",
        "                        base_units = 18\n",
        "                        units = (\n",
        "                            base_units\n",
        "                            * retailer_cat_mult[retailer]\n",
        "                            * brand_mult[brand]\n",
        "                            * region_mult[region]\n",
        "                            * sku_pop[sku]\n",
        "                            * season\n",
        "                        )\n",
        "\n",
        "                        # Promo + feature lifts\n",
        "                        if promo_flag:\n",
        "                            units *= np.random.uniform(1.18, 1.45)\n",
        "                        if feature_display:\n",
        "                            units *= np.random.uniform(1.10, 1.28)\n",
        "\n",
        "                        # Price sensitivity (simple): higher price slightly reduces units\n",
        "                        units *= (1.0 - 0.02 * max(0, (price - base_price)))\n",
        "\n",
        "                        # scale by distribution\n",
        "                        units *= (stores_selling / 500)\n",
        "\n",
        "                        # noise and floor\n",
        "                        units = max(0, np.random.normal(loc=units, scale=max(1.0, units * 0.12)))\n",
        "                        units = int(round(units))\n",
        "\n",
        "                        dollars = round(units * price, 2)\n",
        "\n",
        "                        rows.append({\n",
        "                            \"week_ending\": w.date().isoformat(),\n",
        "                            \"retailer\": retailer,\n",
        "                            \"region\": region,\n",
        "                            \"brand\": brand,\n",
        "                            \"sku\": sku,\n",
        "                            \"price\": price,\n",
        "                            \"units\": units,\n",
        "                            \"dollars\": dollars,\n",
        "                            \"promo_flag\": promo_flag,\n",
        "                            \"feature_display\": feature_display,\n",
        "                            \"stores_selling\": stores_selling,\n",
        "                        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Helpful extra fields\n",
        "    df[\"on_promo\"] = df[\"promo_flag\"].map({0: \"No\", 1: \"Yes\"})\n",
        "    df[\"featured\"] = df[\"feature_display\"].map({0: \"No\", 1: \"Yes\"})\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = generate_mock_scanner_data()\n",
        "df.to_csv(CSV_PATH, index=False)\n",
        "df.head(), df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQkX684Zvi-G",
        "outputId": "b11e1718-162a-4214-f75f-72a187e09624"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(  week_ending retailer   region    brand           sku  price  units  dollars  \\\n",
              " 0  2024-03-03  Walmart  Midwest  Garrett   Cheddar 6oz   5.49     19   104.31   \n",
              " 1  2024-03-03  Walmart  Midwest  Garrett   Caramel 6oz   5.29     24   126.96   \n",
              " 2  2024-03-03  Walmart  Midwest  Garrett      Mix 10oz   8.99     22   197.78   \n",
              " 3  2024-03-03  Walmart  Midwest  Garrett  Caramel 10oz   6.54     21   137.34   \n",
              " 4  2024-03-03  Walmart  Midwest  Garrett  Cheddar 10oz   8.79     19   167.01   \n",
              " \n",
              "    promo_flag  feature_display  stores_selling on_promo featured  \n",
              " 0           0                0             333       No       No  \n",
              " 1           0                0             348       No       No  \n",
              " 2           0                0             347       No       No  \n",
              " 3           1                0             323      Yes       No  \n",
              " 4           0                0             339       No       No  ,\n",
              " (22464, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 2) Category Trend + Share\n",
        "# ============================================\n",
        "df[\"week_ending\"] = pd.to_datetime(df[\"week_ending\"])\n",
        "\n",
        "weekly = df.groupby([\"week_ending\", \"brand\"], as_index=False)[[\"dollars\", \"units\"]].sum()\n",
        "weekly_total = df.groupby([\"week_ending\"], as_index=False)[[\"dollars\", \"units\"]].sum().rename(columns={\"dollars\":\"cat_dollars\",\"units\":\"cat_units\"})\n",
        "weekly = weekly.merge(weekly_total, on=\"week_ending\", how=\"left\")\n",
        "weekly[\"share_dollars\"] = weekly[\"dollars\"] / weekly[\"cat_dollars\"]\n",
        "\n",
        "# Plot Garrett share trend\n",
        "garrett_weekly = weekly[weekly[\"brand\"] == \"Garrett\"].sort_values(\"week_ending\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(garrett_weekly[\"week_ending\"], garrett_weekly[\"share_dollars\"])\n",
        "plt.title(\"Garrett Dollar Share Trend (Synthetic Scanner Data)\")\n",
        "plt.xlabel(\"Week Ending\")\n",
        "plt.ylabel(\"Dollar Share\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "share_path = os.path.join(OUT_DIR, \"garrett_share_trend.png\")\n",
        "plt.savefig(share_path, dpi=200)\n",
        "plt.close()\n",
        "\n",
        "share_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X2DudxI5vuM2",
        "outputId": "afbc1383-fb37-4772-ae7a-3a04cd1dfff0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/outputs/garrett_share_trend.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3) Distribution Whitespace\n",
        "# High category dollars, low Garrett stores_selling\n",
        "# ============================================\n",
        "\n",
        "# Category dollars by retailer (all brands)\n",
        "retailer_cat = df.groupby(\"retailer\", as_index=False)[\"dollars\"].sum().rename(columns={\"dollars\":\"category_dollars\"})\n",
        "\n",
        "# Garrett distribution proxy by retailer (avg stores_selling)\n",
        "garrett_dist = df[df[\"brand\"] == \"Garrett\"].groupby(\"retailer\", as_index=False)[\"stores_selling\"].mean().rename(columns={\"stores_selling\":\"garrett_avg_stores\"})\n",
        "\n",
        "whitespace = retailer_cat.merge(garrett_dist, on=\"retailer\", how=\"left\")\n",
        "\n",
        "# Create a whitespace score: big category dollars + low distribution\n",
        "whitespace[\"category_dollars_rank\"] = whitespace[\"category_dollars\"].rank(ascending=False)\n",
        "whitespace[\"dist_rank_low_is_good\"] = whitespace[\"garrett_avg_stores\"].rank(ascending=True)\n",
        "\n",
        "whitespace[\"whitespace_score\"] = (\n",
        "    (whitespace[\"category_dollars_rank\"].max() - whitespace[\"category_dollars_rank\"] + 1) * 0.6\n",
        "    + (whitespace[\"dist_rank_low_is_good\"].max() - whitespace[\"dist_rank_low_is_good\"] + 1) * 0.4\n",
        ")\n",
        "\n",
        "whitespace = whitespace.sort_values(\"whitespace_score\", ascending=False)\n",
        "\n",
        "whitespace_path = os.path.join(OUT_DIR, \"distribution_whitespace.csv\")\n",
        "whitespace.to_csv(whitespace_path, index=False)\n",
        "\n",
        "whitespace.head(10), whitespace_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz6CcYXNv2Ku",
        "outputId": "f7ca8d45-4cfe-4ff3-a0bb-56dd1485e09c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(    retailer  category_dollars  garrett_avg_stores  category_dollars_rank  \\\n",
              " 5    Walmart         810046.75          356.094551                    1.0   \n",
              " 1     Kroger         565943.59          284.963141                    3.0   \n",
              " 4  Walgreens         282188.84          213.702724                    4.0   \n",
              " 3     Target         638245.72          427.232372                    2.0   \n",
              " 2     Meijer         257343.87          162.729167                    5.0   \n",
              " 0     Costco         252592.46          122.019231                    6.0   \n",
              " \n",
              "    dist_rank_low_is_good  whitespace_score  \n",
              " 5                    5.0               4.4  \n",
              " 1                    4.0               3.6  \n",
              " 4                    3.0               3.4  \n",
              " 3                    6.0               3.4  \n",
              " 2                    2.0               3.2  \n",
              " 0                    1.0               3.0  ,\n",
              " '/content/outputs/distribution_whitespace.csv')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4) Assortment Productivity + Recommendations\n",
        "# dollars/store and units/store, by Garrett SKU and retailer\n",
        "# ============================================\n",
        "\n",
        "g = df[df[\"brand\"] == \"Garrett\"].copy()\n",
        "sku_perf = g.groupby([\"sku\"], as_index=False).agg(\n",
        "    dollars=(\"dollars\", \"sum\"),\n",
        "    units=(\"units\", \"sum\"),\n",
        "    avg_price=(\"price\", \"mean\"),\n",
        "    avg_stores=(\"stores_selling\", \"mean\")\n",
        ")\n",
        "\n",
        "sku_perf[\"dollars_per_store\"] = sku_perf[\"dollars\"] / sku_perf[\"avg_stores\"]\n",
        "sku_perf[\"units_per_store\"] = sku_perf[\"units\"] / sku_perf[\"avg_stores\"]\n",
        "\n",
        "# Simple rules for recs\n",
        "dps_q = sku_perf[\"dollars_per_store\"].quantile([0.33, 0.66]).to_dict()\n",
        "ups_q = sku_perf[\"units_per_store\"].quantile([0.33, 0.66]).to_dict()\n",
        "\n",
        "def recommend(row):\n",
        "    dps = row[\"dollars_per_store\"]\n",
        "    ups = row[\"units_per_store\"]\n",
        "    if dps >= dps_q[0.66] and ups >= ups_q[0.66]:\n",
        "        return \"Expand / Hero SKU\"\n",
        "    if dps <= dps_q[0.33] and ups <= ups_q[0.33]:\n",
        "        return \"Rationalize / Review\"\n",
        "    return \"Maintain\"\n",
        "\n",
        "sku_perf[\"recommendation\"] = sku_perf.apply(recommend, axis=1)\n",
        "sku_perf = sku_perf.sort_values([\"recommendation\", \"dollars_per_store\"], ascending=[True, False])\n",
        "\n",
        "assort_path = os.path.join(OUT_DIR, \"assortment_recommendations.csv\")\n",
        "sku_perf.to_csv(assort_path, index=False)\n",
        "\n",
        "sku_perf, assort_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-o_-ZgIv4st",
        "outputId": "0a18d6df-0062-43f8-980d-37595b3d75f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(            sku    dollars  units  avg_price  avg_stores  dollars_per_store  \\\n",
              " 4      Mix 10oz  144043.55  16770   8.671146  261.213141         551.440672   \n",
              " 5  Variety 12pk  169848.44   9452  18.190080  260.717949         651.464315   \n",
              " 2  Cheddar 10oz  112564.28  13426   8.461546  261.112179         431.095479   \n",
              " 0  Caramel 10oz  102673.20  12774   8.136050  261.080128         393.263174   \n",
              " 3   Cheddar 6oz   80655.58  15556   5.240881  261.411058         308.539282   \n",
              " 1   Caramel 6oz   70703.58  14067   5.078429  261.206731         270.680544   \n",
              " \n",
              "    units_per_store     recommendation  \n",
              " 4        64.200445  Expand / Hero SKU  \n",
              " 5        36.253737           Maintain  \n",
              " 2        51.418513           Maintain  \n",
              " 0        48.927508           Maintain  \n",
              " 3        59.507812           Maintain  \n",
              " 1        53.853896           Maintain  ,\n",
              " '/content/outputs/assortment_recommendations.csv')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5) Pricing + Promotion Performance (Promo ROI proxy)\n",
        "# ============================================\n",
        "\n",
        "promo = g.groupby([\"sku\", \"on_promo\"], as_index=False).agg(\n",
        "    avg_price=(\"price\", \"mean\"),\n",
        "    total_units=(\"units\", \"sum\"),\n",
        "    total_dollars=(\"dollars\", \"sum\")\n",
        ")\n",
        "\n",
        "# Pivot to compute lift\n",
        "pivot = promo.pivot_table(index=\"sku\", columns=\"on_promo\", values=[\"avg_price\", \"total_units\", \"total_dollars\"])\n",
        "pivot.columns = [f\"{a}_{b}\" for a, b in pivot.columns]\n",
        "pivot = pivot.reset_index()\n",
        "\n",
        "# If any SKU never went on promo or never sold off promo, fill with small values to avoid division issues\n",
        "for col in [\"total_units_Yes\",\"total_units_No\",\"avg_price_Yes\",\"avg_price_No\",\"total_dollars_Yes\",\"total_dollars_No\"]:\n",
        "    if col in pivot.columns:\n",
        "        pivot[col] = pivot[col].fillna(0)\n",
        "\n",
        "pivot[\"unit_lift_ratio\"] = np.where(pivot[\"total_units_No\"] > 0, pivot[\"total_units_Yes\"] / pivot[\"total_units_No\"], np.nan)\n",
        "pivot[\"price_delta\"] = pivot[\"avg_price_Yes\"] - pivot[\"avg_price_No\"]\n",
        "\n",
        "promo_roi_path = os.path.join(OUT_DIR, \"promo_roi_table.csv\")\n",
        "pivot.to_csv(promo_roi_path, index=False)\n",
        "\n",
        "pivot.sort_values(\"unit_lift_ratio\", ascending=False).head(10), promo_roi_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD2RfnZfv9QG",
        "outputId": "9ab1729e-7f96-416e-f36d-37f2b320a11f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(            sku  avg_price_No  avg_price_Yes  total_dollars_No  \\\n",
              " 3   Cheddar 6oz          5.49       4.591445          56568.96   \n",
              " 5  Variety 12pk         18.99      15.908827         119883.87   \n",
              " 0  Caramel 10oz          8.49       7.087683          73209.27   \n",
              " 1   Caramel 6oz          5.29       4.403960          52196.43   \n",
              " 2  Cheddar 10oz          8.79       7.346655          84058.77   \n",
              " 4      Mix 10oz          8.99       7.548225         108796.98   \n",
              " \n",
              "    total_dollars_Yes  total_units_No  total_units_Yes  unit_lift_ratio  \\\n",
              " 3           24086.62         10304.0           5252.0         0.509705   \n",
              " 5           49964.57          6313.0           3139.0         0.497228   \n",
              " 0           29463.93          8623.0           4151.0         0.481387   \n",
              " 1           18507.15          9867.0           4200.0         0.425661   \n",
              " 2           28505.51          9563.0           3863.0         0.403953   \n",
              " 4           35246.57         12102.0           4668.0         0.385721   \n",
              " \n",
              "    price_delta  \n",
              " 3    -0.898555  \n",
              " 5    -3.081173  \n",
              " 0    -1.402317  \n",
              " 1    -0.886040  \n",
              " 2    -1.443345  \n",
              " 4    -1.441775  ,\n",
              " '/content/outputs/promo_roi_table.csv')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 6) Simple Price Elasticity Proxy (Regression)\n",
        "# For Garrett overall: units ~ price + promo_flag + feature_display + stores_selling\n",
        "# ============================================\n",
        "\n",
        "# Build a simple model\n",
        "X = g[[\"price\", \"promo_flag\", \"feature_display\", \"stores_selling\"]].copy()\n",
        "y = g[\"units\"].copy()\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "coef = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"coefficient\": model.coef_\n",
        "})\n",
        "intercept = model.intercept_\n",
        "\n",
        "coef_path = os.path.join(OUT_DIR, \"elasticity_regression_coefficients.csv\")\n",
        "coef.to_csv(coef_path, index=False)\n",
        "\n",
        "# Plot price vs units (sample for readability)\n",
        "sample = g.sample(n=min(4000, len(g)), random_state=SEED)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(sample[\"price\"], sample[\"units\"], alpha=0.25)\n",
        "plt.title(\"Price vs Units (Garrett) - Synthetic Data\")\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Units\")\n",
        "plt.tight_layout()\n",
        "price_units_path = os.path.join(OUT_DIR, \"price_vs_units.png\")\n",
        "plt.savefig(price_units_path, dpi=200)\n",
        "plt.close()\n",
        "\n",
        "coef, intercept, coef_path, price_units_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWMfC7plwBzA",
        "outputId": "5215f2d3-2644-4b81-85ec-07979741c7f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(           feature  coefficient\n",
              " 0            price    -0.324898\n",
              " 1       promo_flag     2.376024\n",
              " 2  feature_display     1.919323\n",
              " 3   stores_selling     0.047875,\n",
              " np.float64(0.5155777141486677),\n",
              " '/content/outputs/elasticity_regression_coefficients.csv',\n",
              " '/content/outputs/price_vs_units.png')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Choose a folder in your Drive\n",
        "project_folder = \"/content/drive/MyDrive/garrett-rte-category-analysis\"\n",
        "os.makedirs(project_folder, exist_ok=True)\n",
        "os.makedirs(os.path.join(project_folder, \"data\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(project_folder, \"outputs\"), exist_ok=True)\n",
        "\n",
        "# Copy files\n",
        "import shutil\n",
        "shutil.copy(\"/content/data/rte_scanner_mock.csv\", os.path.join(project_folder, \"data\", \"rte_scanner_mock.csv\"))\n",
        "for f in os.listdir(\"/content/outputs\"):\n",
        "    shutil.copy(os.path.join(\"/content/outputs\", f), os.path.join(project_folder, \"outputs\", f))\n",
        "\n",
        "project_folder\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rhWkAvaBwF6B",
        "outputId": "bad50725-f1e4-4629-8a9b-5cbce474cd38"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/garrett-rte-category-analysis'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}